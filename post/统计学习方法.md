# Headnote

章节中的具体算法，至少要了解模型思想，使用范围，和优缺点。 

# 第一章 统计学习方法概论

## P7 损失函数 有哪些 如何选择

http://www.csuldw.com/2016/03/26/2016-03-26-loss-function/

### ??? 如何选择损失函数

## P9 极大似然估计 等价

https://blog.csdn.net/zengxiantao1994/article/details/72787849

把估计完全未知的概率密度$p(x|w_i)$转化为估计参数，极大似然估计就是一种参数估计方法。当然了，概率密度函数的选取很重要。模型正确，在样本区域无穷时，我们会得到较准确的估计值，如果模型都错了，那估计半天的参数，肯定也没啥意义了。

重要前提：训练样本的分布能代表样本的真实分布。每个样本集中的样本都是所谓独立同分布的随机变量 (iid条件，Independent and identically distributed)，且有充分的训练样本。

https://blog.csdn.net/xmu_jupiter/article/details/44965391

### ??? 利用了极大似然估计的例子、算法

## P9 最大后验概率估计 模型复杂度由模型的先验概率表示时 等价    P14 L1和L2范数 深入理解 作用和原理 以及贝叶斯观点

https://blog.csdn.net/u011508640/article/details/72815981
https://blog.csdn.net/xmu_jupiter/article/details/44996261
https://zhuanlan.zhihu.com/p/32685118

结合P14，复杂模型较小先验概率，简单模型较大先验概率，以达到正则化。

从贝叶斯的角度来看，正则化等价于对模型参数引入 先验分布 。

### ??? 贝叶斯估计 共轭先验

## P15 泛化误差上界推导 ML的可行性

这里只是简单讨论了二分类问题的泛化误差上界。

https://en.wikipedia.org/wiki/Hoeffding%27s_inequality

### ??? Is learning feasible? Learning from Data.

## P18

### ??? 生成方法和判别方法的比较

- 生成方法的学习收敛更快? why
- 存在隐变量时，判别方法不能用? why
- 生产方法不能对数据抽象、定义特征等操作吗?

## P19 机器学习常用衡量指标 适用范围和优缺点对比.

- **classification**: confusion matrix，accuracy，precision，recall，F1 score，PR curve，ROC curve，AUC.
- **regression**: MAE，MSE.

https://blog.csdn.net/mingtian715/article/details/53488094

https://www.zhihu.com/question/30643044 @金戈戈 @qian lv @邓小乔

## P23 习题 极大似然估计 最大后验估计 贝叶斯估计

[共轭先验 wiki](https://zh.wikipedia.org/wiki/%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C) 

https://blog.csdn.net/baimafujinji/article/details/51374202

https://www.jianshu.com/p/bb7bce40a15a

https://zhuanlan.zhihu.com/p/26638720

[贝叶斯估计、最大似然估计、最大后验概率估计](http://noahsnail.com/2018/05/17/2018-05-17-%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1%E3%80%81%E6%9C%80%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1%E3%80%81%E6%9C%80%E5%A4%A7%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E4%BC%B0%E8%AE%A1/) 

[统计学习方法习题试解（第一章）](http://blog.leanote.com/post/sikongdashu8964@gmail.com/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95%E4%B9%A0%E9%A2%98%E8%AF%95%E8%A7%A3%EF%BC%88%E7%AC%AC%E4%B8%80%E7%AB%A0%EF%BC%89) 

### ??? 最大后验估计 vs 贝叶斯估计

### ??? 无信息先验

[Bayes分析中的无信息先验](https://blog.csdn.net/weixin_41929524/article/details/80674219) 

https://mqshen.gitbooks.io/prml/Chapter2/exponential/noninformative_priors.html

# 第二章 感知机

## 习题2.3 凸包与线性可分

https://blog.csdn.net/y954877035/article/details/52210734

### ??? 凸包的定义如何理解如何来的

## ???

P27 Why$\frac{1}{\|w\|}$可忽略? 函数间隔，集合间隔？ 

P31 感知机一定从$w_0=0$开始吗?

P31 不从$w_0=0$开始,可收敛吗?

P31 Why $\|\hat{w}_{opt}\|=1$?

P33 为什么线性不可分时，perceptron不收敛？

P33 感知机算法的原始形式和对偶形式，对偶体现在哪里，如何由原始形式写出对偶形式？与svm的原始形式与对偶形式对应？

徐君 Novikoff定理 也证明了会震荡？

# 第七章 支持向量机

？？？P95 合页损失函数

？？？P95 核技巧，核方法，区别？核方法有哪些？

？？？P95 希尔伯特空间

## P101 最大间隔分离超平面唯一性的推导

$\|w\| \ge c$：$(w,b)$是问题的可行解，满足约束条件。而已知最优解长度等于$c$。

从而有$w_1^* =  \lambda w_2^*$，$\lvert\lambda\rvert=1$：$w=(w_1^*+w_2^*)/2$和$\|w\|=(\|w_1^*\|+\|w_1^*\|)/2$左右平方对比，发现$\cos\lang w_1^*,w_2^* \rang=1$。

## ？？？P103 例7.1怎么算出来结果的

## P225 min或max下的变量是指

固定下面变量外的其他变量，遍历下面的变量，取最小或最大值。

## P227 定理C.2 满足Slater条件，强对偶成立

http://blog.pluskid.org/?p=702

无论 primal problem 是什么形式，dual problem 总是一个 convex optimization 的问题——它的极值是唯一的（如果存在的话）。

而 Slater 条件实际上在这里就等价于是存在这样的一个超平面将数据分隔开来，亦即是“数据是可分的”。当数据不可分是，strong duality 不能成立，不过，这个时候我们寻找分隔平面这个问题本身也就是没有意义的了。至于我们如何通过把数据映射到特征空间中来解决不可分的问题，这个当时已经介绍过了，这里就不多说了。

## P109 惩罚参数C越大，越少容许误分类的点存在。

## ？？？P112 理论上，b的解可能不唯一？？？这个凸优化有多个最优解？

## ？？？P118 7.3.2-7.3.3没看，不太懂

## ？？？P130 (7.116)下方那一段不知道原因。为什么相等，为什么都符合。

## ？？？P130 SMO最后一定收敛于最优解吗？停机条件貌似有点不精确？

## ？？？P134 习题

# 第五章 决策树

## ？？？P57 Why NP hard？

## ？？？贪婪的搜索策略。基于奥卡姆剃刀原理，越是小型的决策树越优于大的决策树。

## P60 (5.3)$H(p)\le\log{n}$

单约束 最大熵

https://blog.csdn.net/qianwenhong/article/details/41479671

## P61 计算信息增益 可见 网络数据挖掘的图示

## P63 为什么偏向选择取值较多的特征？为什么信息增益比会改善这一点？

https://www.zhihu.com/question/22928442 @夕小瑶 和其他人

## ？？？P63 ID3相当于用极大似然法进行概率模型的选择

## ？？？P65 西瓜书 增益律准则对可取值数目较少的属性有所偏好。先找出信息增益高于平均水平的属性，再从中选择增益率最高的。

## ？？？P66 等价于正则化的MLE？

## ？？？P75 习题

# 第8章 提升方法

## ？？？P137 强可学习与弱可学习等价？

## ？？？徐君 弱学习器间必须要有差异性

## ？？？徐君 论文 boosting是函数空间的一个梯度下降

## ？？？P143 泰勒展开推出？
